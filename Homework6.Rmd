---
title: "Homework 6"
author: Bihui Sun
output: github_document
---

```{r}
library(tidyverse)
data=read_csv(file="C:/Users/lenovo/Desktop/p8105/data_import_examples/homicide-data.csv")
data=data%>%
  mutate(city_state=str_c(city,state,sep=","))%>%
  mutate(ifsolved=ifelse(disposition=="Closed by arrest","solved","unsolved"))%>%
  filter(!(city_state%in%c("Dallas,TX","Phoenix,AZ","Kansas City,MO","Tulsa,AL")))%>%
  filter(!(victim_sex=="Unknown"))%>%
  mutate(victim_age=as.numeric(victim_age))%>%
  mutate(victim_race=ifelse(victim_race=="White","white","non-white"))%>%
  mutate(victim_race=as.character(victim_race))%>%
  mutate(victim_race=fct_relevel(victim_race,"white"))%>%
  mutate(ifsolved=as.numeric(ifsolved=="solved"))
data  
data_Bal=data%>%
  filter(city_state=="Baltimore,MD")
model=glm(ifsolved ~ victim_age + victim_race + victim_sex, data = data_Bal, family = binomial())
fit_logistic=broom::tidy(model)
fit_logistic%>%
  mutate(OR=exp(estimate))%>%
  mutate(upperCI=exp(estimate+qnorm(0.975)*std.error))%>%
  mutate(lowerCI=exp(estimate-qnorm(0.975)*std.error))

allcity=data%>%
  select(city_state,ifsolved,victim_age,victim_race,victim_sex)%>%
  group_by(city_state)%>%
  nest()%>%
  mutate(newmodel=map(data,~glm(ifsolved ~ victim_age + victim_race + victim_sex, data= .x,family = binomial())))%>%
  mutate(result=map(newmodel,broom::tidy))%>%
  select(city_state,result)%>%
  unnest()%>%
  mutate(city_OR=exp(estimate))%>%
  mutate(upperCI=exp(estimate+qnorm(0.975)*std.error))%>%
  mutate(lowerCI=exp(estimate-qnorm(0.975)*std.error))%>%
  select(city_state,term,city_OR,upperCI,lowerCI)
allcity
allcity%>%
  mutate(city_state = forcats::fct_reorder(city_state, city_OR))%>%
  ggplot(aes(x=city_state,y=city_OR))+
  geom_point()+
  geom_errorbar(aes(ymin=lowerCI,ymax=upperCI))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))



```


```{r problem2}
library(tidyverse)
library(modelr)
data=read_csv("C:/Users/lenovo/Desktop/p8105/data_import_examples/birthweight.csv")%>%
  mutate(babysex=as.factor(babysex))%>%
  mutate(frace=as.factor(frace))%>%
  mutate(malform=as.factor(malform))%>%
  mutate(mrace=as.factor(mrace))
data=na.omit(data)
data
step(lm(bwt~babysex+bhead+blength+delwt+fincome+frace+gaweeks+malform+menarche+mheight+momage+mrace+parity+pnumlbw+pnumsga+ppbmi+ppwt+smoken+wtgain,data=data),direction="backward")
fit=lm(bwt~babysex+bhead+blength+delwt+fincome+gaweeks+mheight+mrace+parity+ppwt+smoken, data = data)
summary(fit)
data %>% 
  select(bwt,babysex,bhead,blength,delwt,fincome,gaweeks,mheight,mrace,parity,ppwt,smoken)

  
 

data %>% 
  add_residuals(fit)%>%
  
  add_predictions(fit)%>%
  gather(key = name, value = x, -bwt, -pred, -resid) %>%  
  ggplot(aes(x = x, y = bwt)) +  
  geom_segment(aes(xend = x, yend = pred), alpha = .2) +
  geom_point(aes(y = pred), shape = 1) +
  facet_grid(~ name, scales = "free_x") + 
  theme_bw()
  


cv_df =
  crossv_mc(data, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))%>%
  mutate(mod1 = map(train, ~lm(bwt~babysex+bhead+blength+delwt+fincome+gaweeks+mheight+mrace+parity+ppwt+smoken, data = .x)),
         mod2 = map(train, ~lm(bwt ~ blength+gaweeks, data = .x)),
         mod3 = map(train, ~lm(bwt~bhead+blength+babysex+bhead*blength+bhead*babysex+blength*babysex+bhead*babysex*blength,data=.x))) %>% 
  mutate(rmse_mod1 = map2_dbl(mod1, test, ~rmse(model = .x, data = .y)),
         rmse_mod2 = map2_dbl(mod2, test, ~rmse(model = .x, data = .y)),
         rmse_mod3 = map2_dbl(mod3, test, ~rmse(model = .x, data = .y)))
cv_df
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

* The model building process I choose is stepwaise approaches, backward elimination, remove the variable with the greatest p-value one by one , and the predictors left are babysex,bhead,blength,delwt,fincome,gaweeks,mheight,mrace,parity,ppwt,smoken.
From the rmse plot, we can see the first model is the one we want because it has lower rmse.